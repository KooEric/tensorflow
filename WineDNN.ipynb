{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WineDNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OmfHg-GAz05",
        "outputId": "5c476267-be17-48d3-a8e9-c23014370310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 1.9477 - accuracy: 0.4048 \n",
            "Epoch 1: val_loss improved from inf to 1.22229, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 1s 8ms/step - loss: 1.6104 - accuracy: 0.4128 - val_loss: 1.2223 - val_accuracy: 0.5031\n",
            "Epoch 2/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 1.2391 - accuracy: 0.4915\n",
            "Epoch 2: val_loss improved from 1.22229 to 1.17242, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.2191 - accuracy: 0.4848 - val_loss: 1.1724 - val_accuracy: 0.4875\n",
            "Epoch 3/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 1.1788 - accuracy: 0.4728\n",
            "Epoch 3: val_loss did not improve from 1.17242\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.1935 - accuracy: 0.4746 - val_loss: 1.1751 - val_accuracy: 0.4781\n",
            "Epoch 4/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 1.1552 - accuracy: 0.4932\n",
            "Epoch 4: val_loss did not improve from 1.17242\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.1487 - accuracy: 0.4949 - val_loss: 1.1848 - val_accuracy: 0.4688\n",
            "Epoch 5/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 1.1705 - accuracy: 0.4959\n",
            "Epoch 5: val_loss improved from 1.17242 to 1.14475, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.1726 - accuracy: 0.4934 - val_loss: 1.1447 - val_accuracy: 0.4844\n",
            "Epoch 6/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 1.1153 - accuracy: 0.5054\n",
            "Epoch 6: val_loss did not improve from 1.14475\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.1430 - accuracy: 0.4894 - val_loss: 1.1571 - val_accuracy: 0.4625\n",
            "Epoch 7/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 1.1409 - accuracy: 0.4959\n",
            "Epoch 7: val_loss improved from 1.14475 to 1.13233, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.1401 - accuracy: 0.5090 - val_loss: 1.1323 - val_accuracy: 0.5000\n",
            "Epoch 8/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 1.1395 - accuracy: 0.5082\n",
            "Epoch 8: val_loss did not improve from 1.13233\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.1526 - accuracy: 0.5066 - val_loss: 1.1587 - val_accuracy: 0.4656\n",
            "Epoch 9/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 1.1347 - accuracy: 0.5068\n",
            "Epoch 9: val_loss improved from 1.13233 to 1.11812, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.1296 - accuracy: 0.4996 - val_loss: 1.1181 - val_accuracy: 0.4781\n",
            "Epoch 10/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 1.1609 - accuracy: 0.4986\n",
            "Epoch 10: val_loss did not improve from 1.11812\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.1521 - accuracy: 0.5090 - val_loss: 1.1266 - val_accuracy: 0.4781\n",
            "Epoch 11/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 1.0766 - accuracy: 0.5380\n",
            "Epoch 11: val_loss improved from 1.11812 to 1.11653, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.1277 - accuracy: 0.5113 - val_loss: 1.1165 - val_accuracy: 0.5000\n",
            "Epoch 12/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 1.1338 - accuracy: 0.4929\n",
            "Epoch 12: val_loss did not improve from 1.11653\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.1380 - accuracy: 0.4973 - val_loss: 1.1485 - val_accuracy: 0.4656\n",
            "Epoch 13/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 1.1252 - accuracy: 0.5380\n",
            "Epoch 13: val_loss did not improve from 1.11653\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.1216 - accuracy: 0.5137 - val_loss: 1.1222 - val_accuracy: 0.4875\n",
            "Epoch 14/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 1.1212 - accuracy: 0.4821\n",
            "Epoch 14: val_loss improved from 1.11653 to 1.10625, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.1085 - accuracy: 0.4980 - val_loss: 1.1062 - val_accuracy: 0.5031\n",
            "Epoch 15/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 1.1187 - accuracy: 0.5245\n",
            "Epoch 15: val_loss improved from 1.10625 to 1.09702, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.1112 - accuracy: 0.5137 - val_loss: 1.0970 - val_accuracy: 0.5188\n",
            "Epoch 16/300\n",
            "19/40 [=============>................] - ETA: 0s - loss: 1.1542 - accuracy: 0.5000\n",
            "Epoch 16: val_loss did not improve from 1.09702\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.1091 - accuracy: 0.5152 - val_loss: 1.1131 - val_accuracy: 0.5094\n",
            "Epoch 17/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 1.0890 - accuracy: 0.5190\n",
            "Epoch 17: val_loss improved from 1.09702 to 1.07638, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.0943 - accuracy: 0.5285 - val_loss: 1.0764 - val_accuracy: 0.5250\n",
            "Epoch 18/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 1.0655 - accuracy: 0.5455\n",
            "Epoch 18: val_loss improved from 1.07638 to 1.05100, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.0781 - accuracy: 0.5317 - val_loss: 1.0510 - val_accuracy: 0.5437\n",
            "Epoch 19/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 1.0391 - accuracy: 0.5584\n",
            "Epoch 19: val_loss did not improve from 1.05100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.0671 - accuracy: 0.5379 - val_loss: 1.0641 - val_accuracy: 0.5031\n",
            "Epoch 20/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 1.0067 - accuracy: 0.5640\n",
            "Epoch 20: val_loss did not improve from 1.05100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.0428 - accuracy: 0.5496 - val_loss: 1.0877 - val_accuracy: 0.5312\n",
            "Epoch 21/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 1.0245 - accuracy: 0.5489\n",
            "Epoch 21: val_loss did not improve from 1.05100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.0451 - accuracy: 0.5434 - val_loss: 1.0891 - val_accuracy: 0.4938\n",
            "Epoch 22/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 1.0469 - accuracy: 0.5455\n",
            "Epoch 22: val_loss improved from 1.05100 to 1.01957, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.0521 - accuracy: 0.5481 - val_loss: 1.0196 - val_accuracy: 0.5625\n",
            "Epoch 23/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 1.0447 - accuracy: 0.5426\n",
            "Epoch 23: val_loss improved from 1.01957 to 1.01039, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.0457 - accuracy: 0.5434 - val_loss: 1.0104 - val_accuracy: 0.5750\n",
            "Epoch 24/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 1.0317 - accuracy: 0.5710\n",
            "Epoch 24: val_loss did not improve from 1.01039\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.0389 - accuracy: 0.5739 - val_loss: 1.0159 - val_accuracy: 0.5406\n",
            "Epoch 25/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 1.0331 - accuracy: 0.5553\n",
            "Epoch 25: val_loss improved from 1.01039 to 1.00926, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.0302 - accuracy: 0.5575 - val_loss: 1.0093 - val_accuracy: 0.5406\n",
            "Epoch 26/300\n",
            "19/40 [=============>................] - ETA: 0s - loss: 1.0142 - accuracy: 0.5658\n",
            "Epoch 26: val_loss did not improve from 1.00926\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.0155 - accuracy: 0.5559 - val_loss: 1.0688 - val_accuracy: 0.5312\n",
            "Epoch 27/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 1.0892 - accuracy: 0.5298\n",
            "Epoch 27: val_loss improved from 1.00926 to 1.00402, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.0533 - accuracy: 0.5395 - val_loss: 1.0040 - val_accuracy: 0.5750\n",
            "Epoch 28/300\n",
            "20/40 [==============>...............] - ETA: 0s - loss: 1.0207 - accuracy: 0.5750\n",
            "Epoch 28: val_loss improved from 1.00402 to 0.99672, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.0082 - accuracy: 0.5708 - val_loss: 0.9967 - val_accuracy: 0.5719\n",
            "Epoch 29/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9884 - accuracy: 0.5540\n",
            "Epoch 29: val_loss improved from 0.99672 to 0.98969, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.0055 - accuracy: 0.5567 - val_loss: 0.9897 - val_accuracy: 0.5625\n",
            "Epoch 30/300\n",
            "19/40 [=============>................] - ETA: 0s - loss: 0.9737 - accuracy: 0.5806\n",
            "Epoch 30: val_loss did not improve from 0.98969\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9901 - accuracy: 0.5786 - val_loss: 1.0068 - val_accuracy: 0.5500\n",
            "Epoch 31/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9684 - accuracy: 0.5923\n",
            "Epoch 31: val_loss improved from 0.98969 to 0.97435, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9986 - accuracy: 0.5653 - val_loss: 0.9743 - val_accuracy: 0.5906\n",
            "Epoch 32/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 0.9904 - accuracy: 0.5652\n",
            "Epoch 32: val_loss did not improve from 0.97435\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9998 - accuracy: 0.5692 - val_loss: 0.9891 - val_accuracy: 0.5500\n",
            "Epoch 33/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9729 - accuracy: 0.5753\n",
            "Epoch 33: val_loss improved from 0.97435 to 0.97023, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9974 - accuracy: 0.5692 - val_loss: 0.9702 - val_accuracy: 0.5875\n",
            "Epoch 34/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.9900 - accuracy: 0.5598\n",
            "Epoch 34: val_loss improved from 0.97023 to 0.96042, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9900 - accuracy: 0.5598 - val_loss: 0.9604 - val_accuracy: 0.5750\n",
            "Epoch 35/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.9440 - accuracy: 0.5982\n",
            "Epoch 35: val_loss did not improve from 0.96042\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9731 - accuracy: 0.5770 - val_loss: 0.9935 - val_accuracy: 0.5562\n",
            "Epoch 36/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9955 - accuracy: 0.5739\n",
            "Epoch 36: val_loss did not improve from 0.96042\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9738 - accuracy: 0.5817 - val_loss: 0.9726 - val_accuracy: 0.5750\n",
            "Epoch 37/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 1.0080 - accuracy: 0.5685\n",
            "Epoch 37: val_loss did not improve from 0.96042\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9794 - accuracy: 0.5794 - val_loss: 1.0013 - val_accuracy: 0.5437\n",
            "Epoch 38/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9692 - accuracy: 0.5653\n",
            "Epoch 38: val_loss did not improve from 0.96042\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9567 - accuracy: 0.5817 - val_loss: 0.9711 - val_accuracy: 0.5750\n",
            "Epoch 39/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9597 - accuracy: 0.5994\n",
            "Epoch 39: val_loss did not improve from 0.96042\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9640 - accuracy: 0.5880 - val_loss: 0.9682 - val_accuracy: 0.5875\n",
            "Epoch 40/300\n",
            "19/40 [=============>................] - ETA: 0s - loss: 0.9762 - accuracy: 0.5740\n",
            "Epoch 40: val_loss did not improve from 0.96042\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9475 - accuracy: 0.5927 - val_loss: 0.9821 - val_accuracy: 0.5719\n",
            "Epoch 41/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9478 - accuracy: 0.5838\n",
            "Epoch 41: val_loss did not improve from 0.96042\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9643 - accuracy: 0.5715 - val_loss: 0.9726 - val_accuracy: 0.5594\n",
            "Epoch 42/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.9545 - accuracy: 0.5817\n",
            "Epoch 42: val_loss did not improve from 0.96042\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9545 - accuracy: 0.5817 - val_loss: 0.9921 - val_accuracy: 0.5437\n",
            "Epoch 43/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9324 - accuracy: 0.5895\n",
            "Epoch 43: val_loss did not improve from 0.96042\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9429 - accuracy: 0.5841 - val_loss: 0.9707 - val_accuracy: 0.5875\n",
            "Epoch 44/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.9519 - accuracy: 0.5938\n",
            "Epoch 44: val_loss did not improve from 0.96042\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9519 - accuracy: 0.5919 - val_loss: 0.9726 - val_accuracy: 0.5813\n",
            "Epoch 45/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9701 - accuracy: 0.5511\n",
            "Epoch 45: val_loss did not improve from 0.96042\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9614 - accuracy: 0.5723 - val_loss: 0.9694 - val_accuracy: 0.5781\n",
            "Epoch 46/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.9623 - accuracy: 0.5774\n",
            "Epoch 46: val_loss did not improve from 0.96042\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9436 - accuracy: 0.5950 - val_loss: 1.0014 - val_accuracy: 0.5562\n",
            "Epoch 47/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 0.9326 - accuracy: 0.5788\n",
            "Epoch 47: val_loss did not improve from 0.96042\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9493 - accuracy: 0.5825 - val_loss: 0.9748 - val_accuracy: 0.5719\n",
            "Epoch 48/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9396 - accuracy: 0.5923\n",
            "Epoch 48: val_loss did not improve from 0.96042\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9597 - accuracy: 0.5801 - val_loss: 0.9618 - val_accuracy: 0.5875\n",
            "Epoch 49/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9505 - accuracy: 0.5724\n",
            "Epoch 49: val_loss did not improve from 0.96042\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9249 - accuracy: 0.5903 - val_loss: 0.9674 - val_accuracy: 0.6031\n",
            "Epoch 50/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9403 - accuracy: 0.5994\n",
            "Epoch 50: val_loss did not improve from 0.96042\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9298 - accuracy: 0.5973 - val_loss: 0.9989 - val_accuracy: 0.5750\n",
            "Epoch 51/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.9397 - accuracy: 0.5887\n",
            "Epoch 51: val_loss did not improve from 0.96042\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9397 - accuracy: 0.5887 - val_loss: 0.9729 - val_accuracy: 0.5875\n",
            "Epoch 52/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.9320 - accuracy: 0.5908\n",
            "Epoch 52: val_loss did not improve from 0.96042\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9362 - accuracy: 0.5754 - val_loss: 0.9968 - val_accuracy: 0.5875\n",
            "Epoch 53/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.9522 - accuracy: 0.5908\n",
            "Epoch 53: val_loss improved from 0.96042 to 0.95872, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9278 - accuracy: 0.6013 - val_loss: 0.9587 - val_accuracy: 0.6000\n",
            "Epoch 54/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8961 - accuracy: 0.6051\n",
            "Epoch 54: val_loss did not improve from 0.95872\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9145 - accuracy: 0.5973 - val_loss: 0.9778 - val_accuracy: 0.6094\n",
            "Epoch 55/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9344 - accuracy: 0.6222\n",
            "Epoch 55: val_loss did not improve from 0.95872\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9339 - accuracy: 0.6036 - val_loss: 1.0166 - val_accuracy: 0.5625\n",
            "Epoch 56/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.9135 - accuracy: 0.6099\n",
            "Epoch 56: val_loss improved from 0.95872 to 0.95856, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9135 - accuracy: 0.6099 - val_loss: 0.9586 - val_accuracy: 0.6000\n",
            "Epoch 57/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9393 - accuracy: 0.5795\n",
            "Epoch 57: val_loss did not improve from 0.95856\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9330 - accuracy: 0.5919 - val_loss: 0.9836 - val_accuracy: 0.5813\n",
            "Epoch 58/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8928 - accuracy: 0.6136\n",
            "Epoch 58: val_loss did not improve from 0.95856\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9153 - accuracy: 0.5981 - val_loss: 1.0171 - val_accuracy: 0.5469\n",
            "Epoch 59/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 0.9190 - accuracy: 0.5992\n",
            "Epoch 59: val_loss did not improve from 0.95856\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9438 - accuracy: 0.5934 - val_loss: 1.0169 - val_accuracy: 0.5594\n",
            "Epoch 60/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 0.9104 - accuracy: 0.5951\n",
            "Epoch 60: val_loss did not improve from 0.95856\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9197 - accuracy: 0.5966 - val_loss: 0.9785 - val_accuracy: 0.5969\n",
            "Epoch 61/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9115 - accuracy: 0.6207\n",
            "Epoch 61: val_loss did not improve from 0.95856\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9301 - accuracy: 0.6075 - val_loss: 0.9648 - val_accuracy: 0.6187\n",
            "Epoch 62/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 0.9230 - accuracy: 0.5965\n",
            "Epoch 62: val_loss improved from 0.95856 to 0.95722, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9169 - accuracy: 0.6091 - val_loss: 0.9572 - val_accuracy: 0.6094\n",
            "Epoch 63/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9404 - accuracy: 0.5824\n",
            "Epoch 63: val_loss did not improve from 0.95722\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9149 - accuracy: 0.5903 - val_loss: 0.9987 - val_accuracy: 0.5656\n",
            "Epoch 64/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.9162 - accuracy: 0.5962\n",
            "Epoch 64: val_loss did not improve from 0.95722\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9153 - accuracy: 0.5989 - val_loss: 0.9731 - val_accuracy: 0.5781\n",
            "Epoch 65/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9057 - accuracy: 0.6051\n",
            "Epoch 65: val_loss did not improve from 0.95722\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9095 - accuracy: 0.5942 - val_loss: 1.0240 - val_accuracy: 0.5875\n",
            "Epoch 66/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8927 - accuracy: 0.5980\n",
            "Epoch 66: val_loss did not improve from 0.95722\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9426 - accuracy: 0.5801 - val_loss: 0.9674 - val_accuracy: 0.5562\n",
            "Epoch 67/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.9543 - accuracy: 0.5855\n",
            "Epoch 67: val_loss did not improve from 0.95722\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9436 - accuracy: 0.5934 - val_loss: 0.9939 - val_accuracy: 0.5719\n",
            "Epoch 68/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9612 - accuracy: 0.6009\n",
            "Epoch 68: val_loss did not improve from 0.95722\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9428 - accuracy: 0.5989 - val_loss: 0.9669 - val_accuracy: 0.6156\n",
            "Epoch 69/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8719 - accuracy: 0.6165\n",
            "Epoch 69: val_loss did not improve from 0.95722\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8979 - accuracy: 0.6114 - val_loss: 0.9896 - val_accuracy: 0.5813\n",
            "Epoch 70/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8708 - accuracy: 0.6165\n",
            "Epoch 70: val_loss did not improve from 0.95722\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9139 - accuracy: 0.5927 - val_loss: 1.0329 - val_accuracy: 0.5594\n",
            "Epoch 71/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.8929 - accuracy: 0.6138\n",
            "Epoch 71: val_loss did not improve from 0.95722\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8931 - accuracy: 0.6138 - val_loss: 0.9579 - val_accuracy: 0.6031\n",
            "Epoch 72/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8873 - accuracy: 0.5980\n",
            "Epoch 72: val_loss did not improve from 0.95722\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8968 - accuracy: 0.6059 - val_loss: 0.9673 - val_accuracy: 0.6156\n",
            "Epoch 73/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8995 - accuracy: 0.5824\n",
            "Epoch 73: val_loss did not improve from 0.95722\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8779 - accuracy: 0.6130 - val_loss: 0.9709 - val_accuracy: 0.6000\n",
            "Epoch 74/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8907 - accuracy: 0.6051\n",
            "Epoch 74: val_loss improved from 0.95722 to 0.95452, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8975 - accuracy: 0.6075 - val_loss: 0.9545 - val_accuracy: 0.6031\n",
            "Epoch 75/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8868 - accuracy: 0.6136\n",
            "Epoch 75: val_loss did not improve from 0.95452\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8890 - accuracy: 0.6099 - val_loss: 0.9649 - val_accuracy: 0.5938\n",
            "Epoch 76/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8840 - accuracy: 0.6216\n",
            "Epoch 76: val_loss did not improve from 0.95452\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8840 - accuracy: 0.6216 - val_loss: 0.9846 - val_accuracy: 0.6094\n",
            "Epoch 77/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8704 - accuracy: 0.6265\n",
            "Epoch 77: val_loss did not improve from 0.95452\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8884 - accuracy: 0.6138 - val_loss: 0.9906 - val_accuracy: 0.5906\n",
            "Epoch 78/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.8863 - accuracy: 0.6090\n",
            "Epoch 78: val_loss did not improve from 0.95452\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8849 - accuracy: 0.6122 - val_loss: 0.9996 - val_accuracy: 0.5875\n",
            "Epoch 79/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.9124 - accuracy: 0.5997\n",
            "Epoch 79: val_loss did not improve from 0.95452\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9124 - accuracy: 0.5997 - val_loss: 1.0303 - val_accuracy: 0.5750\n",
            "Epoch 80/300\n",
            "36/40 [==========================>...] - ETA: 0s - loss: 0.8794 - accuracy: 0.6198\n",
            "Epoch 80: val_loss did not improve from 0.95452\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8832 - accuracy: 0.6208 - val_loss: 1.0000 - val_accuracy: 0.5844\n",
            "Epoch 81/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.9133 - accuracy: 0.6071\n",
            "Epoch 81: val_loss did not improve from 0.95452\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8740 - accuracy: 0.6200 - val_loss: 1.0407 - val_accuracy: 0.5875\n",
            "Epoch 82/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.9396 - accuracy: 0.6009\n",
            "Epoch 82: val_loss did not improve from 0.95452\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9009 - accuracy: 0.6099 - val_loss: 1.0230 - val_accuracy: 0.5625\n",
            "Epoch 83/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.9290 - accuracy: 0.5952\n",
            "Epoch 83: val_loss did not improve from 0.95452\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9006 - accuracy: 0.6052 - val_loss: 0.9642 - val_accuracy: 0.6219\n",
            "Epoch 84/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8805 - accuracy: 0.6131\n",
            "Epoch 84: val_loss did not improve from 0.95452\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8739 - accuracy: 0.6169 - val_loss: 0.9780 - val_accuracy: 0.5906\n",
            "Epoch 85/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8794 - accuracy: 0.6130\n",
            "Epoch 85: val_loss did not improve from 0.95452\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8794 - accuracy: 0.6130 - val_loss: 0.9894 - val_accuracy: 0.6156\n",
            "Epoch 86/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.8678 - accuracy: 0.6194\n",
            "Epoch 86: val_loss did not improve from 0.95452\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8742 - accuracy: 0.6177 - val_loss: 0.9796 - val_accuracy: 0.5906\n",
            "Epoch 87/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8417 - accuracy: 0.6378\n",
            "Epoch 87: val_loss did not improve from 0.95452\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8773 - accuracy: 0.6271 - val_loss: 0.9565 - val_accuracy: 0.6219\n",
            "Epoch 88/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8537 - accuracy: 0.6222\n",
            "Epoch 88: val_loss did not improve from 0.95452\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8638 - accuracy: 0.6099 - val_loss: 0.9690 - val_accuracy: 0.5906\n",
            "Epoch 89/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8983 - accuracy: 0.6136\n",
            "Epoch 89: val_loss did not improve from 0.95452\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8881 - accuracy: 0.6208 - val_loss: 0.9755 - val_accuracy: 0.6062\n",
            "Epoch 90/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8489 - accuracy: 0.6207\n",
            "Epoch 90: val_loss did not improve from 0.95452\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8722 - accuracy: 0.6138 - val_loss: 0.9659 - val_accuracy: 0.5906\n",
            "Epoch 91/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8569 - accuracy: 0.6177\n",
            "Epoch 91: val_loss did not improve from 0.95452\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8569 - accuracy: 0.6177 - val_loss: 0.9665 - val_accuracy: 0.5906\n",
            "Epoch 92/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8737 - accuracy: 0.6302\n",
            "Epoch 92: val_loss did not improve from 0.95452\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8737 - accuracy: 0.6302 - val_loss: 0.9965 - val_accuracy: 0.6094\n",
            "Epoch 93/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8650 - accuracy: 0.6324\n",
            "Epoch 93: val_loss improved from 0.95452 to 0.95389, saving model to my_checkpoint.ckpt\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8592 - accuracy: 0.6286 - val_loss: 0.9539 - val_accuracy: 0.6313\n",
            "Epoch 94/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.8792 - accuracy: 0.6127\n",
            "Epoch 94: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8667 - accuracy: 0.6200 - val_loss: 0.9642 - val_accuracy: 0.6219\n",
            "Epoch 95/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8763 - accuracy: 0.6067\n",
            "Epoch 95: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8763 - accuracy: 0.6067 - val_loss: 1.0212 - val_accuracy: 0.5844\n",
            "Epoch 96/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8470 - accuracy: 0.6278\n",
            "Epoch 96: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8583 - accuracy: 0.6224 - val_loss: 0.9636 - val_accuracy: 0.6000\n",
            "Epoch 97/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8455 - accuracy: 0.6265\n",
            "Epoch 97: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8589 - accuracy: 0.6185 - val_loss: 0.9622 - val_accuracy: 0.6000\n",
            "Epoch 98/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8440 - accuracy: 0.6325\n",
            "Epoch 98: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8440 - accuracy: 0.6325 - val_loss: 1.0170 - val_accuracy: 0.5906\n",
            "Epoch 99/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8454 - accuracy: 0.6634\n",
            "Epoch 99: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8645 - accuracy: 0.6396 - val_loss: 1.0094 - val_accuracy: 0.6125\n",
            "Epoch 100/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8411 - accuracy: 0.6384\n",
            "Epoch 100: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8385 - accuracy: 0.6435 - val_loss: 0.9878 - val_accuracy: 0.5938\n",
            "Epoch 101/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.7961 - accuracy: 0.6399\n",
            "Epoch 101: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8411 - accuracy: 0.6255 - val_loss: 1.0163 - val_accuracy: 0.5938\n",
            "Epoch 102/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8549 - accuracy: 0.6205\n",
            "Epoch 102: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8560 - accuracy: 0.6286 - val_loss: 0.9588 - val_accuracy: 0.6281\n",
            "Epoch 103/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8344 - accuracy: 0.6414\n",
            "Epoch 103: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8418 - accuracy: 0.6380 - val_loss: 0.9917 - val_accuracy: 0.5875\n",
            "Epoch 104/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8455 - accuracy: 0.6307\n",
            "Epoch 104: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8481 - accuracy: 0.6294 - val_loss: 0.9875 - val_accuracy: 0.5813\n",
            "Epoch 105/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8453 - accuracy: 0.6435\n",
            "Epoch 105: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8455 - accuracy: 0.6396 - val_loss: 0.9944 - val_accuracy: 0.6000\n",
            "Epoch 106/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8586 - accuracy: 0.6295\n",
            "Epoch 106: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8479 - accuracy: 0.6317 - val_loss: 1.0257 - val_accuracy: 0.5781\n",
            "Epoch 107/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8470 - accuracy: 0.6310\n",
            "Epoch 107: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8473 - accuracy: 0.6372 - val_loss: 1.0237 - val_accuracy: 0.5906\n",
            "Epoch 108/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8179 - accuracy: 0.6399\n",
            "Epoch 108: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8312 - accuracy: 0.6286 - val_loss: 1.0329 - val_accuracy: 0.5719\n",
            "Epoch 109/300\n",
            "20/40 [==============>...............] - ETA: 0s - loss: 0.8176 - accuracy: 0.6516\n",
            "Epoch 109: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8559 - accuracy: 0.6364 - val_loss: 0.9717 - val_accuracy: 0.6125\n",
            "Epoch 110/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8360 - accuracy: 0.6506\n",
            "Epoch 110: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8457 - accuracy: 0.6310 - val_loss: 0.9906 - val_accuracy: 0.5969\n",
            "Epoch 111/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8293 - accuracy: 0.6392\n",
            "Epoch 111: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8336 - accuracy: 0.6427 - val_loss: 0.9689 - val_accuracy: 0.6062\n",
            "Epoch 112/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.7972 - accuracy: 0.6591\n",
            "Epoch 112: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8162 - accuracy: 0.6474 - val_loss: 1.0301 - val_accuracy: 0.5906\n",
            "Epoch 113/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8466 - accuracy: 0.6280\n",
            "Epoch 113: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8268 - accuracy: 0.6403 - val_loss: 1.0181 - val_accuracy: 0.5938\n",
            "Epoch 114/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8441 - accuracy: 0.6280\n",
            "Epoch 114: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8601 - accuracy: 0.6263 - val_loss: 0.9963 - val_accuracy: 0.6062\n",
            "Epoch 115/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8455 - accuracy: 0.6271\n",
            "Epoch 115: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8455 - accuracy: 0.6271 - val_loss: 0.9967 - val_accuracy: 0.5906\n",
            "Epoch 116/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8147 - accuracy: 0.6592\n",
            "Epoch 116: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8240 - accuracy: 0.6403 - val_loss: 1.0030 - val_accuracy: 0.5844\n",
            "Epoch 117/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8291 - accuracy: 0.6317\n",
            "Epoch 117: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8291 - accuracy: 0.6317 - val_loss: 0.9897 - val_accuracy: 0.6250\n",
            "Epoch 118/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.7973 - accuracy: 0.6429\n",
            "Epoch 118: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8177 - accuracy: 0.6419 - val_loss: 1.0231 - val_accuracy: 0.6125\n",
            "Epoch 119/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.7982 - accuracy: 0.6652\n",
            "Epoch 119: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8189 - accuracy: 0.6364 - val_loss: 0.9926 - val_accuracy: 0.6125\n",
            "Epoch 120/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8194 - accuracy: 0.6411\n",
            "Epoch 120: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8194 - accuracy: 0.6411 - val_loss: 1.0175 - val_accuracy: 0.5969\n",
            "Epoch 121/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.8120 - accuracy: 0.6357\n",
            "Epoch 121: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8164 - accuracy: 0.6357 - val_loss: 1.0243 - val_accuracy: 0.5750\n",
            "Epoch 122/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8109 - accuracy: 0.6474\n",
            "Epoch 122: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8109 - accuracy: 0.6474 - val_loss: 1.0135 - val_accuracy: 0.6094\n",
            "Epoch 123/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8342 - accuracy: 0.6255\n",
            "Epoch 123: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8342 - accuracy: 0.6255 - val_loss: 1.0436 - val_accuracy: 0.5719\n",
            "Epoch 124/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8154 - accuracy: 0.6443\n",
            "Epoch 124: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8147 - accuracy: 0.6513 - val_loss: 0.9950 - val_accuracy: 0.6062\n",
            "Epoch 125/300\n",
            "36/40 [==========================>...] - ETA: 0s - loss: 0.8072 - accuracy: 0.6432\n",
            "Epoch 125: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8132 - accuracy: 0.6435 - val_loss: 0.9891 - val_accuracy: 0.6219\n",
            "Epoch 126/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8032 - accuracy: 0.6466\n",
            "Epoch 126: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8032 - accuracy: 0.6466 - val_loss: 0.9974 - val_accuracy: 0.6125\n",
            "Epoch 127/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.7993 - accuracy: 0.6577\n",
            "Epoch 127: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8043 - accuracy: 0.6474 - val_loss: 1.0303 - val_accuracy: 0.6156\n",
            "Epoch 128/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8099 - accuracy: 0.6420\n",
            "Epoch 128: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8050 - accuracy: 0.6536 - val_loss: 0.9898 - val_accuracy: 0.5906\n",
            "Epoch 129/300\n",
            "20/40 [==============>...............] - ETA: 0s - loss: 0.7884 - accuracy: 0.6672\n",
            "Epoch 129: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8079 - accuracy: 0.6443 - val_loss: 1.0598 - val_accuracy: 0.5906\n",
            "Epoch 130/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8089 - accuracy: 0.6321\n",
            "Epoch 130: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7873 - accuracy: 0.6497 - val_loss: 0.9903 - val_accuracy: 0.5875\n",
            "Epoch 131/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8023 - accuracy: 0.6622\n",
            "Epoch 131: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8147 - accuracy: 0.6568 - val_loss: 0.9903 - val_accuracy: 0.6062\n",
            "Epoch 132/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.8057 - accuracy: 0.6346\n",
            "Epoch 132: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8074 - accuracy: 0.6349 - val_loss: 1.0334 - val_accuracy: 0.5781\n",
            "Epoch 133/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8070 - accuracy: 0.6295\n",
            "Epoch 133: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7836 - accuracy: 0.6505 - val_loss: 1.0367 - val_accuracy: 0.5781\n",
            "Epoch 134/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8521 - accuracy: 0.6146\n",
            "Epoch 134: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8453 - accuracy: 0.6333 - val_loss: 1.0645 - val_accuracy: 0.5969\n",
            "Epoch 135/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.8172 - accuracy: 0.6392\n",
            "Epoch 135: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8238 - accuracy: 0.6247 - val_loss: 1.0814 - val_accuracy: 0.5719\n",
            "Epoch 136/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.8066 - accuracy: 0.6386\n",
            "Epoch 136: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8022 - accuracy: 0.6427 - val_loss: 1.0385 - val_accuracy: 0.5781\n",
            "Epoch 137/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7901 - accuracy: 0.6536\n",
            "Epoch 137: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7901 - accuracy: 0.6536 - val_loss: 1.0171 - val_accuracy: 0.6219\n",
            "Epoch 138/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.7709 - accuracy: 0.6652\n",
            "Epoch 138: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7792 - accuracy: 0.6544 - val_loss: 1.0415 - val_accuracy: 0.5938\n",
            "Epoch 139/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8121 - accuracy: 0.6101\n",
            "Epoch 139: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7847 - accuracy: 0.6419 - val_loss: 1.0347 - val_accuracy: 0.6156\n",
            "Epoch 140/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.7830 - accuracy: 0.6394\n",
            "Epoch 140: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7864 - accuracy: 0.6411 - val_loss: 1.0603 - val_accuracy: 0.5781\n",
            "Epoch 141/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.8103 - accuracy: 0.6533\n",
            "Epoch 141: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8060 - accuracy: 0.6536 - val_loss: 1.0203 - val_accuracy: 0.5938\n",
            "Epoch 142/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7726 - accuracy: 0.6482\n",
            "Epoch 142: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7778 - accuracy: 0.6474 - val_loss: 1.0176 - val_accuracy: 0.6000\n",
            "Epoch 143/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.7486 - accuracy: 0.6949\n",
            "Epoch 143: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7844 - accuracy: 0.6661 - val_loss: 1.0204 - val_accuracy: 0.6281\n",
            "Epoch 144/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7759 - accuracy: 0.6683\n",
            "Epoch 144: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7788 - accuracy: 0.6669 - val_loss: 1.0273 - val_accuracy: 0.6219\n",
            "Epoch 145/300\n",
            "20/40 [==============>...............] - ETA: 0s - loss: 0.7996 - accuracy: 0.6391\n",
            "Epoch 145: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7957 - accuracy: 0.6427 - val_loss: 1.0549 - val_accuracy: 0.6062\n",
            "Epoch 146/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7701 - accuracy: 0.6615\n",
            "Epoch 146: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7701 - accuracy: 0.6615 - val_loss: 1.0261 - val_accuracy: 0.5969\n",
            "Epoch 147/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.7764 - accuracy: 0.6607\n",
            "Epoch 147: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7756 - accuracy: 0.6654 - val_loss: 1.0424 - val_accuracy: 0.6344\n",
            "Epoch 148/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 0.7738 - accuracy: 0.6617\n",
            "Epoch 148: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7703 - accuracy: 0.6591 - val_loss: 1.0534 - val_accuracy: 0.6094\n",
            "Epoch 149/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.7742 - accuracy: 0.6506\n",
            "Epoch 149: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7652 - accuracy: 0.6536 - val_loss: 1.0257 - val_accuracy: 0.6250\n",
            "Epoch 150/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.7822 - accuracy: 0.6637\n",
            "Epoch 150: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7911 - accuracy: 0.6482 - val_loss: 1.0868 - val_accuracy: 0.5844\n",
            "Epoch 151/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7837 - accuracy: 0.6583\n",
            "Epoch 151: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7837 - accuracy: 0.6583 - val_loss: 1.0473 - val_accuracy: 0.6094\n",
            "Epoch 152/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7600 - accuracy: 0.6630\n",
            "Epoch 152: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7600 - accuracy: 0.6630 - val_loss: 1.0450 - val_accuracy: 0.5875\n",
            "Epoch 153/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7711 - accuracy: 0.6482\n",
            "Epoch 153: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7709 - accuracy: 0.6482 - val_loss: 1.0515 - val_accuracy: 0.6125\n",
            "Epoch 154/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.7433 - accuracy: 0.6711\n",
            "Epoch 154: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7604 - accuracy: 0.6732 - val_loss: 1.0533 - val_accuracy: 0.6187\n",
            "Epoch 155/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.7597 - accuracy: 0.6702\n",
            "Epoch 155: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7611 - accuracy: 0.6732 - val_loss: 1.0813 - val_accuracy: 0.6187\n",
            "Epoch 156/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.7678 - accuracy: 0.6577\n",
            "Epoch 156: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7631 - accuracy: 0.6622 - val_loss: 1.0521 - val_accuracy: 0.6219\n",
            "Epoch 157/300\n",
            "23/40 [================>.............] - ETA: 0s - loss: 0.7726 - accuracy: 0.6630\n",
            "Epoch 157: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7623 - accuracy: 0.6638 - val_loss: 1.0861 - val_accuracy: 0.5969\n",
            "Epoch 158/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.7602 - accuracy: 0.6634\n",
            "Epoch 158: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7661 - accuracy: 0.6591 - val_loss: 1.0756 - val_accuracy: 0.5750\n",
            "Epoch 159/300\n",
            "22/40 [===============>..............] - ETA: 0s - loss: 0.7610 - accuracy: 0.6705\n",
            "Epoch 159: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7639 - accuracy: 0.6724 - val_loss: 1.0617 - val_accuracy: 0.6187\n",
            "Epoch 160/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7651 - accuracy: 0.6615\n",
            "Epoch 160: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7651 - accuracy: 0.6615 - val_loss: 1.0526 - val_accuracy: 0.6219\n",
            "Epoch 161/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7609 - accuracy: 0.6458\n",
            "Epoch 161: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7618 - accuracy: 0.6458 - val_loss: 1.0761 - val_accuracy: 0.6000\n",
            "Epoch 162/300\n",
            "20/40 [==============>...............] - ETA: 0s - loss: 0.7515 - accuracy: 0.6547\n",
            "Epoch 162: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7520 - accuracy: 0.6497 - val_loss: 1.0900 - val_accuracy: 0.5719\n",
            "Epoch 163/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.7363 - accuracy: 0.6830\n",
            "Epoch 163: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7438 - accuracy: 0.6740 - val_loss: 1.1111 - val_accuracy: 0.5969\n",
            "Epoch 164/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.7515 - accuracy: 0.6518\n",
            "Epoch 164: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7300 - accuracy: 0.6685 - val_loss: 1.0700 - val_accuracy: 0.6313\n",
            "Epoch 165/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.7555 - accuracy: 0.6664\n",
            "Epoch 165: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7530 - accuracy: 0.6669 - val_loss: 1.1308 - val_accuracy: 0.5969\n",
            "Epoch 166/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7548 - accuracy: 0.6747\n",
            "Epoch 166: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7548 - accuracy: 0.6747 - val_loss: 1.0555 - val_accuracy: 0.6281\n",
            "Epoch 167/300\n",
            "20/40 [==============>...............] - ETA: 0s - loss: 0.7546 - accuracy: 0.6641\n",
            "Epoch 167: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7465 - accuracy: 0.6677 - val_loss: 1.0907 - val_accuracy: 0.6031\n",
            "Epoch 168/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7525 - accuracy: 0.6763\n",
            "Epoch 168: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7525 - accuracy: 0.6763 - val_loss: 1.1186 - val_accuracy: 0.5969\n",
            "Epoch 169/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.6865 - accuracy: 0.6830\n",
            "Epoch 169: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7309 - accuracy: 0.6654 - val_loss: 1.0927 - val_accuracy: 0.6344\n",
            "Epoch 170/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7485 - accuracy: 0.6635\n",
            "Epoch 170: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7451 - accuracy: 0.6630 - val_loss: 1.0744 - val_accuracy: 0.6125\n",
            "Epoch 171/300\n",
            "34/40 [========================>.....] - ETA: 0s - loss: 0.7438 - accuracy: 0.6765\n",
            "Epoch 171: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7483 - accuracy: 0.6693 - val_loss: 1.1265 - val_accuracy: 0.5938\n",
            "Epoch 172/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.7393 - accuracy: 0.6612\n",
            "Epoch 172: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7403 - accuracy: 0.6591 - val_loss: 1.0963 - val_accuracy: 0.6031\n",
            "Epoch 173/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7478 - accuracy: 0.6701\n",
            "Epoch 173: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7478 - accuracy: 0.6701 - val_loss: 1.0771 - val_accuracy: 0.6156\n",
            "Epoch 174/300\n",
            "20/40 [==============>...............] - ETA: 0s - loss: 0.7471 - accuracy: 0.6719\n",
            "Epoch 174: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7358 - accuracy: 0.6787 - val_loss: 1.1465 - val_accuracy: 0.6125\n",
            "Epoch 175/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7363 - accuracy: 0.6685\n",
            "Epoch 175: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.6685 - val_loss: 1.1088 - val_accuracy: 0.5969\n",
            "Epoch 176/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7332 - accuracy: 0.6740\n",
            "Epoch 176: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7332 - accuracy: 0.6740 - val_loss: 1.0659 - val_accuracy: 0.6125\n",
            "Epoch 177/300\n",
            "20/40 [==============>...............] - ETA: 0s - loss: 0.7758 - accuracy: 0.6344\n",
            "Epoch 177: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7424 - accuracy: 0.6685 - val_loss: 1.1351 - val_accuracy: 0.6125\n",
            "Epoch 178/300\n",
            "36/40 [==========================>...] - ETA: 0s - loss: 0.7332 - accuracy: 0.6892\n",
            "Epoch 178: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7477 - accuracy: 0.6826 - val_loss: 1.1315 - val_accuracy: 0.6125\n",
            "Epoch 179/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.7378 - accuracy: 0.6698\n",
            "Epoch 179: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7290 - accuracy: 0.6747 - val_loss: 1.1573 - val_accuracy: 0.6125\n",
            "Epoch 180/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.7240 - accuracy: 0.6661\n",
            "Epoch 180: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7253 - accuracy: 0.6661 - val_loss: 1.0974 - val_accuracy: 0.6062\n",
            "Epoch 181/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7216 - accuracy: 0.6867\n",
            "Epoch 181: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7202 - accuracy: 0.6880 - val_loss: 1.1343 - val_accuracy: 0.6000\n",
            "Epoch 182/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7119 - accuracy: 0.6739\n",
            "Epoch 182: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7135 - accuracy: 0.6740 - val_loss: 1.2072 - val_accuracy: 0.5844\n",
            "Epoch 183/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.6951 - accuracy: 0.6860\n",
            "Epoch 183: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7340 - accuracy: 0.6669 - val_loss: 1.1723 - val_accuracy: 0.6000\n",
            "Epoch 184/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.7378 - accuracy: 0.6807\n",
            "Epoch 184: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7322 - accuracy: 0.6818 - val_loss: 1.1475 - val_accuracy: 0.6125\n",
            "Epoch 185/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.7062 - accuracy: 0.6933\n",
            "Epoch 185: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7061 - accuracy: 0.6935 - val_loss: 1.1417 - val_accuracy: 0.6031\n",
            "Epoch 186/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7460 - accuracy: 0.6779\n",
            "Epoch 186: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7460 - accuracy: 0.6779 - val_loss: 1.1963 - val_accuracy: 0.5656\n",
            "Epoch 187/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.7473 - accuracy: 0.6354\n",
            "Epoch 187: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7325 - accuracy: 0.6661 - val_loss: 1.1671 - val_accuracy: 0.5875\n",
            "Epoch 188/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.7134 - accuracy: 0.6935\n",
            "Epoch 188: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7189 - accuracy: 0.6833 - val_loss: 1.2171 - val_accuracy: 0.6031\n",
            "Epoch 189/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.7272 - accuracy: 0.6801\n",
            "Epoch 189: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7312 - accuracy: 0.6787 - val_loss: 1.1622 - val_accuracy: 0.5969\n",
            "Epoch 190/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7107 - accuracy: 0.6802\n",
            "Epoch 190: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7107 - accuracy: 0.6802 - val_loss: 1.1335 - val_accuracy: 0.6125\n",
            "Epoch 191/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7180 - accuracy: 0.6883\n",
            "Epoch 191: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7186 - accuracy: 0.6888 - val_loss: 1.1422 - val_accuracy: 0.6062\n",
            "Epoch 192/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7233 - accuracy: 0.6819\n",
            "Epoch 192: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7209 - accuracy: 0.6833 - val_loss: 1.1759 - val_accuracy: 0.5906\n",
            "Epoch 193/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7100 - accuracy: 0.6875\n",
            "Epoch 193: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7113 - accuracy: 0.6888 - val_loss: 1.1847 - val_accuracy: 0.6156\n",
            "Epoch 194/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.6990\n",
            "Epoch 194: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6951 - accuracy: 0.6990 - val_loss: 1.2006 - val_accuracy: 0.6094\n",
            "Epoch 195/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.7037 - accuracy: 0.6883\n",
            "Epoch 195: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7053 - accuracy: 0.6888 - val_loss: 1.1651 - val_accuracy: 0.5813\n",
            "Epoch 196/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7048 - accuracy: 0.6959\n",
            "Epoch 196: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7048 - accuracy: 0.6959 - val_loss: 1.1762 - val_accuracy: 0.6062\n",
            "Epoch 197/300\n",
            "34/40 [========================>.....] - ETA: 0s - loss: 0.6992 - accuracy: 0.6912\n",
            "Epoch 197: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7109 - accuracy: 0.6904 - val_loss: 1.1402 - val_accuracy: 0.6094\n",
            "Epoch 198/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7068 - accuracy: 0.6857\n",
            "Epoch 198: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7068 - accuracy: 0.6857 - val_loss: 1.1661 - val_accuracy: 0.6125\n",
            "Epoch 199/300\n",
            "36/40 [==========================>...] - ETA: 0s - loss: 0.6959 - accuracy: 0.6918\n",
            "Epoch 199: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7004 - accuracy: 0.6841 - val_loss: 1.1799 - val_accuracy: 0.6000\n",
            "Epoch 200/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.6880\n",
            "Epoch 200: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.6880 - val_loss: 1.1686 - val_accuracy: 0.6094\n",
            "Epoch 201/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.7086 - accuracy: 0.6943\n",
            "Epoch 201: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7081 - accuracy: 0.6943 - val_loss: 1.1459 - val_accuracy: 0.6125\n",
            "Epoch 202/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.6979\n",
            "Epoch 202: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.6990 - val_loss: 1.1955 - val_accuracy: 0.6250\n",
            "Epoch 203/300\n",
            "34/40 [========================>.....] - ETA: 0s - loss: 0.6868 - accuracy: 0.6994\n",
            "Epoch 203: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.6966 - val_loss: 1.1845 - val_accuracy: 0.6219\n",
            "Epoch 204/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.6545 - accuracy: 0.7188\n",
            "Epoch 204: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.7052 - val_loss: 1.2196 - val_accuracy: 0.6031\n",
            "Epoch 205/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6875 - accuracy: 0.6919\n",
            "Epoch 205: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.6919 - val_loss: 1.2340 - val_accuracy: 0.6250\n",
            "Epoch 206/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6903 - accuracy: 0.6939\n",
            "Epoch 206: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6994 - accuracy: 0.6904 - val_loss: 1.2135 - val_accuracy: 0.6094\n",
            "Epoch 207/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.6512 - accuracy: 0.7083\n",
            "Epoch 207: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.6943 - val_loss: 1.2311 - val_accuracy: 0.6000\n",
            "Epoch 208/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6945 - accuracy: 0.6896\n",
            "Epoch 208: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.6896 - val_loss: 1.2299 - val_accuracy: 0.6094\n",
            "Epoch 209/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7012 - accuracy: 0.6904\n",
            "Epoch 209: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7012 - accuracy: 0.6904 - val_loss: 1.3295 - val_accuracy: 0.6156\n",
            "Epoch 210/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6779 - accuracy: 0.7037\n",
            "Epoch 210: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.7037 - val_loss: 1.2571 - val_accuracy: 0.5719\n",
            "Epoch 211/300\n",
            "36/40 [==========================>...] - ETA: 0s - loss: 0.6910 - accuracy: 0.6866\n",
            "Epoch 211: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7114 - accuracy: 0.6779 - val_loss: 1.2429 - val_accuracy: 0.6187\n",
            "Epoch 212/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.6919 - accuracy: 0.6834\n",
            "Epoch 212: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6980 - accuracy: 0.6849 - val_loss: 1.2700 - val_accuracy: 0.6250\n",
            "Epoch 213/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.7152 - accuracy: 0.6841\n",
            "Epoch 213: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7172 - accuracy: 0.6802 - val_loss: 1.2535 - val_accuracy: 0.6125\n",
            "Epoch 214/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6895 - accuracy: 0.6979\n",
            "Epoch 214: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.6998 - val_loss: 1.2343 - val_accuracy: 0.5969\n",
            "Epoch 215/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.6758 - accuracy: 0.7128\n",
            "Epoch 215: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.7045 - val_loss: 1.2500 - val_accuracy: 0.6062\n",
            "Epoch 216/300\n",
            "36/40 [==========================>...] - ETA: 0s - loss: 0.6797 - accuracy: 0.7014\n",
            "Epoch 216: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6777 - accuracy: 0.7037 - val_loss: 1.2014 - val_accuracy: 0.6187\n",
            "Epoch 217/300\n",
            "36/40 [==========================>...] - ETA: 0s - loss: 0.6499 - accuracy: 0.7057\n",
            "Epoch 217: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.6998 - val_loss: 1.1843 - val_accuracy: 0.6125\n",
            "Epoch 218/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.6686 - accuracy: 0.6905\n",
            "Epoch 218: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.6888 - val_loss: 1.2725 - val_accuracy: 0.6094\n",
            "Epoch 219/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.6629 - accuracy: 0.7009\n",
            "Epoch 219: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.6943 - val_loss: 1.3064 - val_accuracy: 0.6000\n",
            "Epoch 220/300\n",
            "36/40 [==========================>...] - ETA: 0s - loss: 0.6812 - accuracy: 0.6918\n",
            "Epoch 220: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6780 - accuracy: 0.6935 - val_loss: 1.2668 - val_accuracy: 0.6219\n",
            "Epoch 221/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.6616 - accuracy: 0.7015\n",
            "Epoch 221: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6645 - accuracy: 0.6982 - val_loss: 1.2640 - val_accuracy: 0.6031\n",
            "Epoch 222/300\n",
            "36/40 [==========================>...] - ETA: 0s - loss: 0.6739 - accuracy: 0.6927\n",
            "Epoch 222: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6700 - accuracy: 0.6974 - val_loss: 1.2835 - val_accuracy: 0.6062\n",
            "Epoch 223/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6848 - accuracy: 0.6883\n",
            "Epoch 223: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.6888 - val_loss: 1.2861 - val_accuracy: 0.6062\n",
            "Epoch 224/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.7045 - accuracy: 0.6727\n",
            "Epoch 224: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7024 - accuracy: 0.6763 - val_loss: 1.2445 - val_accuracy: 0.5781\n",
            "Epoch 225/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.6989 - accuracy: 0.6850\n",
            "Epoch 225: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6974 - accuracy: 0.6826 - val_loss: 1.2612 - val_accuracy: 0.5906\n",
            "Epoch 226/300\n",
            "35/40 [=========================>....] - ETA: 0s - loss: 0.6513 - accuracy: 0.7036\n",
            "Epoch 226: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.7037 - val_loss: 1.2693 - val_accuracy: 0.5938\n",
            "Epoch 227/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.6736 - accuracy: 0.7221\n",
            "Epoch 227: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.7185 - val_loss: 1.2361 - val_accuracy: 0.6156\n",
            "Epoch 228/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.6651 - accuracy: 0.7035\n",
            "Epoch 228: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6667 - accuracy: 0.7029 - val_loss: 1.2682 - val_accuracy: 0.6187\n",
            "Epoch 229/300\n",
            "36/40 [==========================>...] - ETA: 0s - loss: 0.6755 - accuracy: 0.7057\n",
            "Epoch 229: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.7131 - val_loss: 1.2709 - val_accuracy: 0.5969\n",
            "Epoch 230/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6721 - accuracy: 0.6947\n",
            "Epoch 230: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6747 - accuracy: 0.6959 - val_loss: 1.2948 - val_accuracy: 0.6062\n",
            "Epoch 231/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6609 - accuracy: 0.7107\n",
            "Epoch 231: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6609 - accuracy: 0.7107 - val_loss: 1.2881 - val_accuracy: 0.5938\n",
            "Epoch 232/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6387 - accuracy: 0.7154\n",
            "Epoch 232: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6387 - accuracy: 0.7154 - val_loss: 1.3259 - val_accuracy: 0.5938\n",
            "Epoch 233/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6745 - accuracy: 0.6779\n",
            "Epoch 233: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.6787 - val_loss: 1.3246 - val_accuracy: 0.6031\n",
            "Epoch 234/300\n",
            "34/40 [========================>.....] - ETA: 0s - loss: 0.6626 - accuracy: 0.7050\n",
            "Epoch 234: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.7045 - val_loss: 1.3344 - val_accuracy: 0.5875\n",
            "Epoch 235/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.6458 - accuracy: 0.7155\n",
            "Epoch 235: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.7162 - val_loss: 1.3449 - val_accuracy: 0.5875\n",
            "Epoch 236/300\n",
            "36/40 [==========================>...] - ETA: 0s - loss: 0.6714 - accuracy: 0.6944\n",
            "Epoch 236: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.6998 - val_loss: 1.3489 - val_accuracy: 0.6000\n",
            "Epoch 237/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6608 - accuracy: 0.7107\n",
            "Epoch 237: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.7107 - val_loss: 1.3286 - val_accuracy: 0.5938\n",
            "Epoch 238/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6383 - accuracy: 0.7115\n",
            "Epoch 238: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6419 - accuracy: 0.7107 - val_loss: 1.3493 - val_accuracy: 0.6156\n",
            "Epoch 239/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6518 - accuracy: 0.7217\n",
            "Epoch 239: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.7217 - val_loss: 1.4047 - val_accuracy: 0.5875\n",
            "Epoch 240/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.6584 - accuracy: 0.6968\n",
            "Epoch 240: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6611 - accuracy: 0.6982 - val_loss: 1.3575 - val_accuracy: 0.6219\n",
            "Epoch 241/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7117 - accuracy: 0.6667\n",
            "Epoch 241: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7095 - accuracy: 0.6685 - val_loss: 1.3227 - val_accuracy: 0.5813\n",
            "Epoch 242/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6700 - accuracy: 0.6935\n",
            "Epoch 242: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6700 - accuracy: 0.6935 - val_loss: 1.3033 - val_accuracy: 0.6156\n",
            "Epoch 243/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6412 - accuracy: 0.7284\n",
            "Epoch 243: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.7248 - val_loss: 1.3247 - val_accuracy: 0.6250\n",
            "Epoch 244/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.6379 - accuracy: 0.7145\n",
            "Epoch 244: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6362 - accuracy: 0.7162 - val_loss: 1.3281 - val_accuracy: 0.6250\n",
            "Epoch 245/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6588 - accuracy: 0.7013\n",
            "Epoch 245: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.7013 - val_loss: 1.2718 - val_accuracy: 0.6156\n",
            "Epoch 246/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.6497 - accuracy: 0.7113\n",
            "Epoch 246: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.7154 - val_loss: 1.3301 - val_accuracy: 0.6313\n",
            "Epoch 247/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6450 - accuracy: 0.7193\n",
            "Epoch 247: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.7193 - val_loss: 1.4405 - val_accuracy: 0.6000\n",
            "Epoch 248/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6489 - accuracy: 0.6979\n",
            "Epoch 248: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6493 - accuracy: 0.6990 - val_loss: 1.3181 - val_accuracy: 0.6313\n",
            "Epoch 249/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.6618 - accuracy: 0.7039\n",
            "Epoch 249: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6598 - accuracy: 0.7045 - val_loss: 1.3182 - val_accuracy: 0.6062\n",
            "Epoch 250/300\n",
            "36/40 [==========================>...] - ETA: 0s - loss: 0.6370 - accuracy: 0.7092\n",
            "Epoch 250: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6321 - accuracy: 0.7107 - val_loss: 1.3191 - val_accuracy: 0.6000\n",
            "Epoch 251/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6398 - accuracy: 0.7091\n",
            "Epoch 251: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6362 - accuracy: 0.7115 - val_loss: 1.3898 - val_accuracy: 0.5906\n",
            "Epoch 252/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.6532 - accuracy: 0.7039\n",
            "Epoch 252: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.7240 - val_loss: 1.3582 - val_accuracy: 0.6125\n",
            "Epoch 253/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.6354 - accuracy: 0.7262\n",
            "Epoch 253: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.7248 - val_loss: 1.4044 - val_accuracy: 0.5844\n",
            "Epoch 254/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6541 - accuracy: 0.7188\n",
            "Epoch 254: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6571 - accuracy: 0.7177 - val_loss: 1.3468 - val_accuracy: 0.5875\n",
            "Epoch 255/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6452 - accuracy: 0.7027\n",
            "Epoch 255: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.7045 - val_loss: 1.4060 - val_accuracy: 0.6031\n",
            "Epoch 256/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.6261 - accuracy: 0.7294\n",
            "Epoch 256: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.7318 - val_loss: 1.3529 - val_accuracy: 0.6281\n",
            "Epoch 257/300\n",
            "35/40 [=========================>....] - ETA: 0s - loss: 0.6166 - accuracy: 0.7241\n",
            "Epoch 257: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6216 - accuracy: 0.7232 - val_loss: 1.4222 - val_accuracy: 0.6125\n",
            "Epoch 258/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.6247 - accuracy: 0.7247\n",
            "Epoch 258: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6243 - accuracy: 0.7248 - val_loss: 1.4800 - val_accuracy: 0.5781\n",
            "Epoch 259/300\n",
            "35/40 [=========================>....] - ETA: 0s - loss: 0.6269 - accuracy: 0.7214\n",
            "Epoch 259: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.7209 - val_loss: 1.3068 - val_accuracy: 0.5938\n",
            "Epoch 260/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.6570 - accuracy: 0.7154\n",
            "Epoch 260: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.7131 - val_loss: 1.4186 - val_accuracy: 0.6125\n",
            "Epoch 261/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6512 - accuracy: 0.7035\n",
            "Epoch 261: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6480 - accuracy: 0.7045 - val_loss: 1.3610 - val_accuracy: 0.5719\n",
            "Epoch 262/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6427 - accuracy: 0.7131\n",
            "Epoch 262: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6418 - accuracy: 0.7123 - val_loss: 1.4048 - val_accuracy: 0.6313\n",
            "Epoch 263/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.6300 - accuracy: 0.7212\n",
            "Epoch 263: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6277 - accuracy: 0.7217 - val_loss: 1.3986 - val_accuracy: 0.6281\n",
            "Epoch 264/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.6339 - accuracy: 0.7230\n",
            "Epoch 264: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.7240 - val_loss: 1.3260 - val_accuracy: 0.6000\n",
            "Epoch 265/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.6108 - accuracy: 0.7297\n",
            "Epoch 265: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6117 - accuracy: 0.7326 - val_loss: 1.4276 - val_accuracy: 0.6125\n",
            "Epoch 266/300\n",
            "35/40 [=========================>....] - ETA: 0s - loss: 0.6162 - accuracy: 0.7223\n",
            "Epoch 266: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.7185 - val_loss: 1.4095 - val_accuracy: 0.5969\n",
            "Epoch 267/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6227 - accuracy: 0.7236\n",
            "Epoch 267: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.7217 - val_loss: 1.3979 - val_accuracy: 0.6219\n",
            "Epoch 268/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.6374 - accuracy: 0.7105\n",
            "Epoch 268: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.7138 - val_loss: 1.4128 - val_accuracy: 0.6125\n",
            "Epoch 269/300\n",
            "35/40 [=========================>....] - ETA: 0s - loss: 0.6162 - accuracy: 0.7196\n",
            "Epoch 269: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.7209 - val_loss: 1.4476 - val_accuracy: 0.6062\n",
            "Epoch 270/300\n",
            "36/40 [==========================>...] - ETA: 0s - loss: 0.6188 - accuracy: 0.7300\n",
            "Epoch 270: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.7295 - val_loss: 1.4882 - val_accuracy: 0.6219\n",
            "Epoch 271/300\n",
            "30/40 [=====================>........] - ETA: 0s - loss: 0.5887 - accuracy: 0.7427\n",
            "Epoch 271: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6112 - accuracy: 0.7217 - val_loss: 1.4584 - val_accuracy: 0.6313\n",
            "Epoch 272/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.6430 - accuracy: 0.7179\n",
            "Epoch 272: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.7201 - val_loss: 1.3803 - val_accuracy: 0.5781\n",
            "Epoch 273/300\n",
            "36/40 [==========================>...] - ETA: 0s - loss: 0.6279 - accuracy: 0.7170\n",
            "Epoch 273: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6212 - accuracy: 0.7201 - val_loss: 1.4480 - val_accuracy: 0.6062\n",
            "Epoch 274/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5990 - accuracy: 0.7443\n",
            "Epoch 274: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5990 - accuracy: 0.7443 - val_loss: 1.5456 - val_accuracy: 0.6156\n",
            "Epoch 275/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.6475 - accuracy: 0.6993\n",
            "Epoch 275: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.6998 - val_loss: 1.4845 - val_accuracy: 0.5781\n",
            "Epoch 276/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.6386 - accuracy: 0.7154\n",
            "Epoch 276: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.7162 - val_loss: 1.4743 - val_accuracy: 0.5969\n",
            "Epoch 277/300\n",
            "35/40 [=========================>....] - ETA: 0s - loss: 0.6094 - accuracy: 0.7143\n",
            "Epoch 277: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6154 - accuracy: 0.7154 - val_loss: 1.4882 - val_accuracy: 0.6125\n",
            "Epoch 278/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.6358 - accuracy: 0.7272\n",
            "Epoch 278: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.7334 - val_loss: 1.4043 - val_accuracy: 0.6000\n",
            "Epoch 279/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6147 - accuracy: 0.7260\n",
            "Epoch 279: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.7240 - val_loss: 1.4441 - val_accuracy: 0.6406\n",
            "Epoch 280/300\n",
            "21/40 [==============>...............] - ETA: 0s - loss: 0.5382 - accuracy: 0.7574\n",
            "Epoch 280: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5865 - accuracy: 0.7295 - val_loss: 1.4178 - val_accuracy: 0.6125\n",
            "Epoch 281/300\n",
            "33/40 [=======================>......] - ETA: 0s - loss: 0.6258 - accuracy: 0.7254\n",
            "Epoch 281: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6202 - accuracy: 0.7357 - val_loss: 1.5492 - val_accuracy: 0.6000\n",
            "Epoch 282/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.6164 - accuracy: 0.7294\n",
            "Epoch 282: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6208 - accuracy: 0.7232 - val_loss: 1.4891 - val_accuracy: 0.5938\n",
            "Epoch 283/300\n",
            "35/40 [=========================>....] - ETA: 0s - loss: 0.6292 - accuracy: 0.7214\n",
            "Epoch 283: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6369 - accuracy: 0.7115 - val_loss: 1.4663 - val_accuracy: 0.6094\n",
            "Epoch 284/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.6246 - accuracy: 0.7245\n",
            "Epoch 284: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.7217 - val_loss: 1.4529 - val_accuracy: 0.6219\n",
            "Epoch 285/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.6458 - accuracy: 0.7105\n",
            "Epoch 285: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6535 - accuracy: 0.7084 - val_loss: 1.5235 - val_accuracy: 0.6094\n",
            "Epoch 286/300\n",
            "37/40 [==========================>...] - ETA: 0s - loss: 0.6334 - accuracy: 0.7111\n",
            "Epoch 286: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.7123 - val_loss: 1.5193 - val_accuracy: 0.5969\n",
            "Epoch 287/300\n",
            "36/40 [==========================>...] - ETA: 0s - loss: 0.6092 - accuracy: 0.7465\n",
            "Epoch 287: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.7467 - val_loss: 1.5346 - val_accuracy: 0.5938\n",
            "Epoch 288/300\n",
            "33/40 [=======================>......] - ETA: 0s - loss: 0.6127 - accuracy: 0.7301\n",
            "Epoch 288: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6248 - accuracy: 0.7240 - val_loss: 1.4518 - val_accuracy: 0.6313\n",
            "Epoch 289/300\n",
            "32/40 [=======================>......] - ETA: 0s - loss: 0.5820 - accuracy: 0.7324\n",
            "Epoch 289: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5991 - accuracy: 0.7287 - val_loss: 1.5308 - val_accuracy: 0.6438\n",
            "Epoch 290/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6023 - accuracy: 0.7380\n",
            "Epoch 290: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5995 - accuracy: 0.7389 - val_loss: 1.4408 - val_accuracy: 0.6156\n",
            "Epoch 291/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.5870 - accuracy: 0.7410\n",
            "Epoch 291: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.5850 - accuracy: 0.7435 - val_loss: 1.5065 - val_accuracy: 0.6094\n",
            "Epoch 292/300\n",
            "34/40 [========================>.....] - ETA: 0s - loss: 0.5901 - accuracy: 0.7371\n",
            "Epoch 292: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5914 - accuracy: 0.7342 - val_loss: 1.5380 - val_accuracy: 0.5969\n",
            "Epoch 293/300\n",
            "31/40 [======================>.......] - ETA: 0s - loss: 0.5892 - accuracy: 0.7248\n",
            "Epoch 293: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5933 - accuracy: 0.7248 - val_loss: 1.5182 - val_accuracy: 0.6000\n",
            "Epoch 294/300\n",
            "31/40 [======================>.......] - ETA: 0s - loss: 0.6200 - accuracy: 0.7208\n",
            "Epoch 294: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.6065 - accuracy: 0.7271 - val_loss: 1.5348 - val_accuracy: 0.6062\n",
            "Epoch 295/300\n",
            "33/40 [=======================>......] - ETA: 0s - loss: 0.6001 - accuracy: 0.7415\n",
            "Epoch 295: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6022 - accuracy: 0.7365 - val_loss: 1.5544 - val_accuracy: 0.5875\n",
            "Epoch 296/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.5917 - accuracy: 0.7204\n",
            "Epoch 296: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.5944 - accuracy: 0.7162 - val_loss: 1.5881 - val_accuracy: 0.6031\n",
            "Epoch 297/300\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.5956 - accuracy: 0.7356\n",
            "Epoch 297: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5895 - accuracy: 0.7389 - val_loss: 1.4833 - val_accuracy: 0.6156\n",
            "Epoch 298/300\n",
            "36/40 [==========================>...] - ETA: 0s - loss: 0.5803 - accuracy: 0.7587\n",
            "Epoch 298: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5810 - accuracy: 0.7568 - val_loss: 1.4309 - val_accuracy: 0.6219\n",
            "Epoch 299/300\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.5802 - accuracy: 0.7599\n",
            "Epoch 299: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5925 - accuracy: 0.7514 - val_loss: 1.5874 - val_accuracy: 0.6031\n",
            "Epoch 300/300\n",
            "36/40 [==========================>...] - ETA: 0s - loss: 0.5963 - accuracy: 0.7387\n",
            "Epoch 300: val_loss did not improve from 0.95389\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5947 - accuracy: 0.7342 - val_loss: 1.5247 - val_accuracy: 0.6125\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "redwine = pd.read_csv(\"/content/winequality-red.csv\", sep=\";\")\n",
        "redwine_X = redwine.iloc[:, :-1]\n",
        "redwine_y = redwine.iloc[:, -1] - 3\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_X, test_X, train_y, test_y = train_test_split(redwine_X, redwine_y, \n",
        "                                                    test_size=0.2)\n",
        "\n",
        "    \n",
        "def solution_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        Dense(256, activation='relu', input_shape=(11,)),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(6, activation='softmax'),\n",
        "        ])\n",
        "\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "    \n",
        "    checkpoint_path = \"my_checkpoint.ckpt\"\n",
        "    checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n",
        "                             save_weights_only=True, \n",
        "                             save_best_only=True, \n",
        "                             monitor='val_loss', \n",
        "                             verbose=1)\n",
        "    \n",
        "    history = model.fit(train_X, train_y.to_numpy(),\n",
        "                    validation_data=(test_X, test_y.to_numpy()),\n",
        "                    epochs=300,\n",
        "                    callbacks=[checkpoint],\n",
        "                   )\n",
        "    \n",
        "    model.load_weights(checkpoint_path)\n",
        "    return model\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    # model.save(\"TF4-sarcasm.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_X, test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vypkWi0SA9Pu",
        "outputId": "1c284c3e-83c3-4f45-8585-a6ba9c0fd0b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9539 - accuracy: 0.6313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(6,4))\n",
        "ax1.plot(history.history['loss'], 'r-', label=\"train_loss\")\n",
        "ax1.set_ylabel(\"train loss\")\n",
        "ax1.legend()\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(history.history['accuracy'],'g:',label=\"train_acc\")\n",
        "ax2.set_ylabel(\"train acc\")\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "NeHg4EeyA9fQ",
        "outputId": "07b8baef-5051-4887-f330-d9ec012f9d51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IHjlPniNEB-l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}