{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarcasm",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import urllib\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def solution_model():\n",
        "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json'\n",
        "    urllib.request.urlretrieve(url, 'sarcasm.json')\n",
        "\n",
        "    vocab_size = 1000\n",
        "    embedding_dim = 16\n",
        "    max_length = 120\n",
        "    trunc_type='post'\n",
        "    padding_type='post'\n",
        "    oov_tok = \"<OOV>\"\n",
        "    training_size = 20000\n",
        "\n",
        "    with open('sarcasm.json') as f:\n",
        "        datas = json.load(f)\n",
        "\n",
        "    sentences = []\n",
        "    labels = []\n",
        "\n",
        "    for data in datas:\n",
        "        sentences.append(data['headline'])\n",
        "        labels.append(data['is_sarcastic'])\n",
        "    \n",
        "    train_sentences = sentences[:training_size]\n",
        "    train_labels = labels[:training_size]\n",
        "\n",
        "    validation_sentences = sentences[training_size:]\n",
        "    validation_labels = labels[training_size:]\n",
        "\n",
        "    tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "    tokenizer.fit_on_texts(train_sentences)\n",
        "\n",
        "    train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "    validation_sequences = tokenizer.texts_to_sequences(validation_sentences)\n",
        "\n",
        "    train_padded = pad_sequences(train_sequences, maxlen = max_length, truncating = trunc_type, padding = padding_type)\n",
        "    validation_padded = pad_sequences(validation_sequences, maxlen = max_length, truncating = trunc_type, padding = padding_type)\n",
        "\n",
        "    train_labels = np.array(train_labels)\n",
        "    validation_labels = np.array(validation_labels)\n",
        "\n",
        "    model = Sequential([\n",
        "                        Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "                        Bidirectional(LSTM(64, return_sequences=True)),\n",
        "                        Bidirectional(LSTM(128, return_sequences=True)),\n",
        "                        Bidirectional(LSTM(128, return_sequences=True)),\n",
        "                        Bidirectional(LSTM(64)),\n",
        "                        Dense(128, activation='relu'),\n",
        "                        Dense(64, activation='relu'),\n",
        "                        Dense(32, activation='relu'),\n",
        "                        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "    checkpoint_path = 'my_checkpoint_ckpt'\n",
        "    checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                 save_weights_only = True,\n",
        "                                 save_best_only = True,\n",
        "                                 monitor = 'val_loss',\n",
        "                                 verbose = 1)\n",
        "    \n",
        "    model.fit(train_padded, train_labels,\n",
        "              validation_data = (validation_padded, validation_labels),\n",
        "              callbacks = [checkpoint],\n",
        "              epochs = 20)\n",
        "    model.load_weights(checkpoint_path)\n",
        "\n",
        "    return model\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    model.save(\"TF4-sarcasm.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfPrZGMlonFB",
        "outputId": "57ecd595-8155-4505-f5c2-464e43ce890c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.4564 - acc: 0.7752\n",
            "Epoch 1: val_loss improved from inf to 0.40732, saving model to my_checkpoint_ckpt\n",
            "625/625 [==============================] - 42s 54ms/step - loss: 0.4565 - acc: 0.7750 - val_loss: 0.4073 - val_acc: 0.7973\n",
            "Epoch 2/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3627 - acc: 0.8351\n",
            "Epoch 2: val_loss improved from 0.40732 to 0.37299, saving model to my_checkpoint_ckpt\n",
            "625/625 [==============================] - 31s 50ms/step - loss: 0.3627 - acc: 0.8351 - val_loss: 0.3730 - val_acc: 0.8289\n",
            "Epoch 3/20\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.3328 - acc: 0.8509\n",
            "Epoch 3: val_loss did not improve from 0.37299\n",
            "625/625 [==============================] - 31s 50ms/step - loss: 0.3328 - acc: 0.8508 - val_loss: 0.3735 - val_acc: 0.8307\n",
            "Epoch 4/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3131 - acc: 0.8612\n",
            "Epoch 4: val_loss did not improve from 0.37299\n",
            "625/625 [==============================] - 32s 52ms/step - loss: 0.3131 - acc: 0.8612 - val_loss: 0.3881 - val_acc: 0.8259\n",
            "Epoch 5/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2981 - acc: 0.8715\n",
            "Epoch 5: val_loss did not improve from 0.37299\n",
            "625/625 [==============================] - 31s 49ms/step - loss: 0.2981 - acc: 0.8715 - val_loss: 0.3730 - val_acc: 0.8308\n",
            "Epoch 6/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2846 - acc: 0.8785\n",
            "Epoch 6: val_loss did not improve from 0.37299\n",
            "625/625 [==============================] - 31s 50ms/step - loss: 0.2846 - acc: 0.8785 - val_loss: 0.3777 - val_acc: 0.8268\n",
            "Epoch 7/20\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.2769 - acc: 0.8806\n",
            "Epoch 7: val_loss did not improve from 0.37299\n",
            "625/625 [==============================] - 30s 49ms/step - loss: 0.2770 - acc: 0.8806 - val_loss: 0.3881 - val_acc: 0.8204\n",
            "Epoch 8/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2660 - acc: 0.8860\n",
            "Epoch 8: val_loss did not improve from 0.37299\n",
            "625/625 [==============================] - 31s 49ms/step - loss: 0.2660 - acc: 0.8860 - val_loss: 0.4042 - val_acc: 0.8265\n",
            "Epoch 9/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2565 - acc: 0.8906\n",
            "Epoch 9: val_loss did not improve from 0.37299\n",
            "625/625 [==============================] - 30s 48ms/step - loss: 0.2565 - acc: 0.8906 - val_loss: 0.3949 - val_acc: 0.8214\n",
            "Epoch 10/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2511 - acc: 0.8934\n",
            "Epoch 10: val_loss did not improve from 0.37299\n",
            "625/625 [==============================] - 30s 48ms/step - loss: 0.2511 - acc: 0.8934 - val_loss: 0.3931 - val_acc: 0.8231\n",
            "Epoch 11/20\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.2452 - acc: 0.8966\n",
            "Epoch 11: val_loss did not improve from 0.37299\n",
            "625/625 [==============================] - 30s 48ms/step - loss: 0.2455 - acc: 0.8964 - val_loss: 0.4436 - val_acc: 0.8228\n",
            "Epoch 12/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2360 - acc: 0.9003\n",
            "Epoch 12: val_loss did not improve from 0.37299\n",
            "625/625 [==============================] - 30s 48ms/step - loss: 0.2360 - acc: 0.9003 - val_loss: 0.4290 - val_acc: 0.8216\n",
            "Epoch 13/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2299 - acc: 0.9044\n",
            "Epoch 13: val_loss did not improve from 0.37299\n",
            "625/625 [==============================] - 30s 48ms/step - loss: 0.2299 - acc: 0.9044 - val_loss: 0.4568 - val_acc: 0.8232\n",
            "Epoch 14/20\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.2190 - acc: 0.9095\n",
            "Epoch 14: val_loss did not improve from 0.37299\n",
            "625/625 [==============================] - 31s 49ms/step - loss: 0.2191 - acc: 0.9094 - val_loss: 0.4893 - val_acc: 0.8174\n",
            "Epoch 15/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2113 - acc: 0.9120\n",
            "Epoch 15: val_loss did not improve from 0.37299\n",
            "625/625 [==============================] - 30s 48ms/step - loss: 0.2113 - acc: 0.9120 - val_loss: 0.4502 - val_acc: 0.8182\n",
            "Epoch 16/20\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.2071 - acc: 0.9144\n",
            "Epoch 16: val_loss did not improve from 0.37299\n",
            "625/625 [==============================] - 30s 48ms/step - loss: 0.2072 - acc: 0.9143 - val_loss: 0.4918 - val_acc: 0.8156\n",
            "Epoch 17/20\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.1967 - acc: 0.9196\n",
            "Epoch 17: val_loss did not improve from 0.37299\n",
            "625/625 [==============================] - 30s 47ms/step - loss: 0.1966 - acc: 0.9197 - val_loss: 0.4733 - val_acc: 0.8188\n",
            "Epoch 18/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1922 - acc: 0.9200\n",
            "Epoch 18: val_loss did not improve from 0.37299\n",
            "625/625 [==============================] - 30s 48ms/step - loss: 0.1922 - acc: 0.9200 - val_loss: 0.5537 - val_acc: 0.8149\n",
            "Epoch 19/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1865 - acc: 0.9229\n",
            "Epoch 19: val_loss did not improve from 0.37299\n",
            "625/625 [==============================] - 30s 48ms/step - loss: 0.1865 - acc: 0.9229 - val_loss: 0.5154 - val_acc: 0.8106\n",
            "Epoch 20/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1781 - acc: 0.9257\n",
            "Epoch 20: val_loss did not improve from 0.37299\n",
            "625/625 [==============================] - 32s 51ms/step - loss: 0.1781 - acc: 0.9257 - val_loss: 0.5412 - val_acc: 0.8079\n"
          ]
        }
      ]
    }
  ]
}